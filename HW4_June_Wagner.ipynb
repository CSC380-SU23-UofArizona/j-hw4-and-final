{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "902c7503",
   "metadata": {},
   "source": [
    "# Homework 04: Midway Check-in Final Project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "631c10a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# June Wagner\n",
    "# Homework 04\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead35716",
   "metadata": {},
   "source": [
    "## 2. Data Collection\n",
    "### 2.1 Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a757ce42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a short description of the dataset (200+ words). Think on: where data was collected from, how, whose data it is, what\n",
    "# are the main features of the dataset, how old it is, how often it is updated... etc.\n",
    "\n",
    "# Dataset: \"Game Recommendations on Steam\" - by Anton Kozyriev, last updated 13 December 2023 (accessed 29 April 2024).\n",
    "# Update frequency: semi-monthly basis; last updated 5 months ago.\n",
    "# https://www.kaggle.com/datasets/antonkozyriev/game-recommendations-on-steam\n",
    "# All data was collected from Steam, an online games store / games library application run by Valve Corporation.\n",
    "# https://store.steampowered.com/\n",
    "#\n",
    "# There are four files in total: games.csv, games_metadata.json, recommendations.csv, and users.csv. According to the dataset's\n",
    "# webpage, these files represent over 41 million user recommendations of games on Steam; according to my exploration, there are\n",
    "# some 50,000 games represented--some of which are only Downloadable Content (DLC) or musical Original Soundtrack (OST).\n",
    "# \n",
    "# games.csv contains a list of games on Steam as they appear in a snapshot--even their discounts (a temporary variable).\n",
    "#    Each entry has an app_id that is unique, a title (does not contain commas), a date it was released on Steam,\n",
    "#    which operating systems it is available on (Windows, Mac, Linux), a rating (e.g. positive, mixed, overwhelmingly negative),\n",
    "#    the ratio of positive ratings (e.g. 90), the number of user-submitted reviews, the price (before and after any discount),\n",
    "#    and whether it is available on the Steam Deck (almost all are).\n",
    "# \n",
    "# games_metadata.json is a metadata .json file that adds colorful information to each game entry, like developer-submitted\n",
    "#    descriptions of their game(s) and selected genre tags for the games. Many games lack a description and/or a genre tag.\n",
    "# \n",
    "# recommendations.csv: a many-to-many relation between games and users, with positive and negative (TRUE or FALSE) reviews.\n",
    "#    Each review has a recorded app_id to identify the game being reviewed, and a review_id to identify the individual review.\n",
    "#    Although \"helpful\" and \"funny\" are included metrics, they represent other-user engagement with a given review.\n",
    "#    The reveiwer's user_id is included, and their number of hours played on the given game is also given (as low as 0, rarely).\n",
    "#    A date is also included, which could be helpful for quantifying a more-recent review as worth more than a less-recent one.\n",
    "#\n",
    "# users.csv: a list of users, their number of products (games), and their number of reviews. Very few have 0 games or 0 reviews.\n",
    "#\n",
    "# According to the description on Kaggle, the dataset is built from information already accessible to the public, and all \n",
    "# users are assigned an anonymized user ID.\n",
    "\n",
    "# ***All of this information is further expanded in 3.1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a68b898",
   "metadata": {},
   "source": [
    "### 2.2 Dataset Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1c0396c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2.1: Download the dataset to the folder data.\n",
    "\n",
    "# Don't forget to do this, June :)\n",
    "# ** Add data to the git ignore file, so it is not pushed to the repository (because it's not our data to upload/distribute)..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dceb841c",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "### 3.1 Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ee2eecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1.1 Perform some initial data exploration to understand the dataset better.\n",
    "\n",
    "# games.csv:\n",
    "#    games.csv contains a list of games on Steam as they appear in a snapshot--even their discounts (a temporary variable)\n",
    "#    app_id - a critical information point that identifies each entry to a unique number\n",
    "#    title - much less important; some of these titles contain bizarre characters, especially around trademark symbols... badly translated into ascii?\n",
    "#    date_release - release date in (m)m/(d)d/yyyy format. We might filter out entries beyond 2020 since that's where the RepresentMe database stops.\n",
    "#    win - available on a Windows platform. \n",
    "#    mac - available on a Mac platform.\n",
    "#    linux - available on a Linux platform. (Least common)\n",
    "#       If a game is triple-negative (not win, mac, or linux) it seems to be an Soundtrack and/or Artbook.\n",
    "#          * I should remove these entries and ignore their app_id in other .csv data files.\n",
    "#\n",
    "#    rating - 9 Categories, by this general rubric:\n",
    "#           - Overwhelmingly Positive: 95%+ positive reviews; 500+ reviews\n",
    "#           - Very Positive          : 85%+ positive reviews; 50+ reviews\n",
    "#           - Positive               : 80%+ positive reviews; 10+ reviews\n",
    "#           - Mostly Positive        : 70%+ positive reviews; 10+ reviews\n",
    "#           - Mixed                  : 40%+ positive reviews; 10+ reviews\n",
    "#           - Mostly Negative        : 20%+ positive reviews; 10+ reviews\n",
    "#           - Negative               : 00%+ positive reviews; 10+ reviews\n",
    "#           - Very Negative          : 00%+ positive reviews; 50+ reviews\n",
    "#           - Overwhelmingly Negative: 00%+ positive reviews; 500+ reviews\n",
    "#       If a game is Mostly Negative or worse, I should probably strike it from the model? We are trying to recommend good game experiences.\n",
    "#    positive_ratio - the ratio of positive reviews, accurate to 2 digits (e.g. 94% or 11%).\n",
    "#       I think that this is relatively redundant to the \"rating\", especially because \"rating\" includes a \"confidence\" (i.e. 'very')\n",
    "#    user_reviews - the number of reviews a game has had (min: 10 max: 7494460). \n",
    "#       There are no games with fewer than 10 reviews here, and this is useful because a game needs 10+ reviews to qualify for \"rating\"\n",
    "#       \n",
    "#       * I think that 'rating' makes for a decent enough metric that it is okay to mostly ignore the positive_ratio and user_reviews,\n",
    "#          especially since it is a useful product of those two and represents both positivity and confidence of a positive experience.\n",
    "#\n",
    "#    price_final - price after a discount is applied to the price_original.\n",
    "#    price_original - the original price of the game, before any potential discount is applied.\n",
    "#    discount - the percentage (min: 0%; max: 90%) discount on the game.\n",
    "#        This is a mostly trivial section of the data, but it is useful to report price and/or discount as part of the game insofar as\n",
    "#        an end user would like to know how much a game costs before following through with a purchase. I would consider this to be\n",
    "#        a more decorative sort of data, not very important to what we're trying to accomplish here.\n",
    "#    steam_deck - TRUE or FALSE: compatible with the Steam Deck gaming platform. There are exactly two games that are FALSE.\n",
    "\n",
    "# games_metadata.json: a metadata .json file that adds information to each game entry.\n",
    "#     app_id: a unique number assigned to each game, perfectly 1-for-1 to the game's entry in games.csv app_id.\n",
    "#     description: flavor text that may or may not exist (i.e. some entries are null), as a description for the game.\n",
    "#     tags: game genres as an array (e.g. Action, Adventure, Simulation, RTS, 2D, Rougelike); some entries are empty / null.\n",
    "#        \n",
    "#        * This could be useful information except that so many games don't have tags and/or a description! \n",
    "#        I think it is worth delivering this info to the end-user at least; it could be worth exploring a user's \n",
    "#        preference for genres if the many-to-many users.csv file doesn't deliver similarly important information.\n",
    "\n",
    "# recommendations.csv: a many-to-many relation between games and users, with positive and negative (TRUE or FALSE) reviews.\n",
    "#     app_id: a unique number assigned to each game, exactly the same as in games.csv and games_metadata.json ...\n",
    "#     helpful: the number of other-user reactions to this review that indicate it is \"helpful\" (range: 0, 2 to 16163),\n",
    "#        more than half of these entries are \"0\", but that doesn't necessarily mean these reviews are unhelpful.\n",
    "#        Potentially just that this user review hasn't had many eyes on it.\n",
    "#     funny: the number of other-user reactions to this review that indicate it is \"funny\" (range: 0, 2 to 8818),\n",
    "#        more than 3/4 of these entries are \"0\". This might not be an especially useful metric except that it means that\n",
    "#        other users have read and engaged with this review.\n",
    "#     date: the date a review was published. This could be helpful, since more recent reviews are more relevant to the current\n",
    "#        release of the game than older reviews.\n",
    "#     is_recommended: TRUE or FALSE. \"FALSE\" (i.e. negative) is fewer than 1/10 of the reviews. A negative review is much less common\n",
    "#        than a positive one. Are negative reviews useful for steering our decisions? Maybe even more than positive reviews?\n",
    "#        After all, a negative review means a lot more than simply no review at all. A user must really go out of their way for it!\n",
    "#        But they are much less common than positive reviews; positive reviews will likely form the majority basis for what we \n",
    "#        want to accomplish here.\n",
    "#     hours: the number of hours a user has in a game, (range: 0 to 999.9; clearly truncating at 999.9 as so many users will have\n",
    "#        more than 1000 hours); this can be seen as a \"confidence\" of the review. A review with 0 hours may be worth less than a\n",
    "#        review at 999.9+ hours.\n",
    "#     user_id: a number assigned to each unique user; this number can repeat--this means that that user has made multiple reviews.\n",
    "#     review_id: a number assigned to each unique review.\n",
    "\n",
    "# users.csv: a list of users, their number of products (games), and their number of reviews.\n",
    "#     user_id: a number assigned to each unique user. Just as in recommendations.csv.\n",
    "#     products: the number of games the user has (range: 0, 2 to 21112). Very few are 0.\n",
    "#        I think that users that have \"0\" products actually 'used' to own one or more games, but now do not own any (refund?)\n",
    "#        (Maybe confiscation for violation of Steam's Terms of Service?)\n",
    "#     reviews: the number of reviews this user has produced (range: 0 to 1762); very few are 0.\n",
    "#        I wonder if the users with \"0\" reviews actually created a review that was removed? Maybe for moderation reasons (profanity)?\n",
    "#     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2366f270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1.2 Address missing data, if any, by appropriately identifying and quantifying missing values in the dataset.\n",
    "\n",
    "# By visual inspection (messing around in Excel) the data shows no null values except in the .json, where there are many \n",
    "# games with no description and/or tags (genre). The dataset does not have users with 1 product, games with <10 reviews, etc.,\n",
    "# so it would appear that the dataset has already had some cleaning done to it and I won't be able to tell if some values\n",
    "# were changed. I wonder if the lack of \"1\" as a datapoint in some columns is because it could be read as \"TRUE\" in some \n",
    "# programs. I assume that some--but not all--outliers are already dealt with.\n",
    "\n",
    "\n",
    "# WIP: \n",
    "\n",
    "# See 3.1.5 for checking for further missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75c72a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1.3 Apply suitable techniques to handle missing values (e.g. imputation, exclusion) based on a logical approach.\n",
    "# 3.1.4 Justify the chosen method in 50+ words.\n",
    "\n",
    "# This dataset is already quite clean, as shown in 3.1.5\n",
    "# While the games_metadata.json does have quite a few missing values, it is already not going to be relied on. If it could\n",
    "# have at least one tag for (most) games, I might see about using imputation to classify the remainder as \"untagged\" and see\n",
    "# if tags could be used to help recommend games, but in the current circumstances this doesn't make much sense.\n",
    "\n",
    "# I suppose I am excluding information from the games_metadata.json altogether for its incompleteness. If it is used, it will\n",
    "# be in order to deliver flavorful information to the end user about the generated recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c28fed1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50872 entries, 0 to 50871\n",
      "Data columns (total 13 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   app_id          50872 non-null  int64  \n",
      " 1   title           50872 non-null  object \n",
      " 2   date_release    50872 non-null  object \n",
      " 3   win             50872 non-null  bool   \n",
      " 4   mac             50872 non-null  bool   \n",
      " 5   linux           50872 non-null  bool   \n",
      " 6   rating          50872 non-null  object \n",
      " 7   positive_ratio  50872 non-null  int64  \n",
      " 8   user_reviews    50872 non-null  int64  \n",
      " 9   price_final     50872 non-null  float64\n",
      " 10  price_original  50872 non-null  float64\n",
      " 11  discount        50872 non-null  float64\n",
      " 12  steam_deck      50872 non-null  bool   \n",
      "dtypes: bool(4), float64(3), int64(3), object(3)\n",
      "memory usage: 3.7+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "app_id            0\n",
       "title             0\n",
       "date_release      0\n",
       "win               0\n",
       "mac               0\n",
       "linux             0\n",
       "rating            0\n",
       "positive_ratio    0\n",
       "user_reviews      0\n",
       "price_final       0\n",
       "price_original    0\n",
       "discount          0\n",
       "steam_deck        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.1.5.a Checking for missing values with code. (games.csv)\n",
    "games_df = pd.read_csv(\"games.csv\")\n",
    "\n",
    "\n",
    "games_df.info() # get a simple summary\n",
    "games_df.isna().sum() # if all numbers are 0, there are no null values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc7c065c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14306064 entries, 0 to 14306063\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Dtype\n",
      "---  ------    -----\n",
      " 0   user_id   int64\n",
      " 1   products  int64\n",
      " 2   reviews   int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 327.4 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "user_id     0\n",
       "products    0\n",
       "reviews     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.1.5.b Checking for missing values with code. (users.csv)\n",
    "users_df = pd.read_csv(\"users.csv\")\n",
    "\n",
    "users_df.info() # get a simple summary\n",
    "users_df.isna().sum() # if all numbers are 0, there are no null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097eb704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1.5.c Checking for missing values with code. (recommendations.csv)   *** WARNING: THIS TAKES TIME! 2.2+ GB data into memory!\n",
    "recom_df = pd.read_csv(\"recommendations.csv\")\n",
    "\n",
    "recom_df.info() # get a simple summary\n",
    "recom_df.isna().sum() # if all numbers are 0, there are no null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72b6618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1.5.d Checking for missing values with code. (games_metadata.json)\n",
    "gmeta_df = pd.read_json(\"games_metadata.json\", lines = True)  # *** Throws ValueError for \"trailing data\" if not lines = True\n",
    "\n",
    "gmeta_df.info() # get a simple summary\n",
    "gmeta_df.isna().sum() # if all numbers are 0, there are no null values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f32b51",
   "metadata": {},
   "source": [
    "### 3.2 Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f0c8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2.a Check for outliers: games_df\n",
    "\n",
    "# *** I want to use games_df as an example of finding outliers and excluding them.\n",
    "#     This is already a very clean dataset, so removing datapoints shouldn't be done just because they skew distribution.\n",
    "#     This is just how I would do it if I was going to :)\n",
    "\n",
    "# Then, I will apply math (interquartile range * some threshold, like 1.5) to find specific outliers.\n",
    "# Finally, I will deal with these outliers logically.\n",
    "pd.options.display.float_format = '{:.0f}'.format # This option suppresses Pandas's scientific notation, allows 0 decimal.\n",
    "\n",
    "# I will start with games_df\n",
    "games_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621a15b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2.a games_df outliers check continued\n",
    "\n",
    "# We should ignore app_id. This might as well be a string.\n",
    "\n",
    "# positive_ratio: I think there will be outliers below the 25th quartile. It might be worth excluding these poorly-rated games.\n",
    "# user_reviews: There are absolutely outliers in user_reviews above the 75th quartile. I don't think its worth excluding \n",
    "#               games that have a ton of reviews; this just means that they're more popular, and we merely should make sure\n",
    "#               that we don't necessarily count a very high number of reviews as much more valuable than the 75th quartile of\n",
    "#               reviews (7494460 should be relatively similar to 206).\n",
    "#\n",
    "#               In fact, Steam uses the thresholds 10+, 50+, 500+ reviews to determine confidence of reviews.\n",
    "#               Consider that the ratio of 500 to 206 is 2.43; this is a pretty reasonable tolerance (standard is 1.5). \n",
    "#               Maybe we make sure down the line that we treat 7494460 reviews the same as 500 reviews?\n",
    "#               The way to do this would probably be to rely on the strings in\n",
    "#               \"rating\": Overwhelmingly positive, Very positive, Positive, ..., Overwhelmingly negative.\n",
    "\n",
    "# We will be ignoring price_final, price_original, and discount. These columns don't matter to us--we just want games' quality.\n",
    "\n",
    "q1_posratio = games_df[\"positive_ratio\"].quantile(0.25)\n",
    "q3_posratio = games_df[\"positive_ratio\"].quantile(0.75)\n",
    "iqr_posratio = q3_posratio - q1_posratio  # 91 - 67 = 24\n",
    "floor_posratio = q1_posratio - iqr_posratio * 1.5  # 1.5 is the threshold here. It is somewhat arbitrary.\n",
    "#print(floor_posratio) # = 31\n",
    "posratio_outliers = games_df[(games_df[\"positive_ratio\"] < floor_posratio)] # If positive_ratio < 31, then exclude.\n",
    "\n",
    "display(posratio_outliers)\n",
    "print(\"As expected, we get a dataframe full of quite negatively-rated games. We will exclude these (Removal).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c56f68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2.a games_df positive_ratio outliers dealt with, to illustrate an example.\n",
    "\n",
    "display(games_df.drop(posratio_outliers.index).sort_values(by = \"positive_ratio\"))\n",
    "\n",
    "print(f\"With this removal, our games_df in progress would be without the {posratio_outliers.shape[0]} extremely negatively-rated outliers.\")\n",
    "print(f\"However, this isn't actually a desirable outcome--these outliers aren't because of some measurement error!\")\n",
    "print(f\"Rather, we should keep these poorly-rated games in because they're just another part of our data.\")\n",
    "print(f\"If ultimately our work ends up recommending the 'outlier' negatively-rated games, then we know something is wrong.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246b8b7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 3.2.a games_df outlier discussion conclusion\n",
    "\n",
    "# Ultimately, we shouldn't be just removing these otherwise valid data points so that we get a more normal-looking distribution.\n",
    "# But at least we have shown how it could be done :)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2e4d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2.b Now users_df gets described and examined for outliers.\n",
    "display(users_df.describe())\n",
    "\n",
    "plt.boxplot(users_df[\"products\"])\n",
    "plt.title(\"Products Boxplot\")\n",
    "plt.show()\n",
    "\n",
    "plt.boxplot(users_df[\"reviews\"])\n",
    "plt.title(\"Reviews Boxplot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5dbf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2.b users_df examination for outliers continued\n",
    "\n",
    "# So we see that these are extremely skewed. The majority of users have 127 or fewer Steam products, and have made 3 or\n",
    "# fewer reviews. Yet there are all these outliers with a huge amount of products or reviews!\n",
    "\n",
    "# Thinking ahead, we might actually want to remove some of these outliers ... they are likely bots or mal-actor users who \n",
    "# intend to make tons of reviews for some potentially nefarious, selfish, or silly purpose. There are, for instance, review\n",
    "# bots that rate games on whether or not they contain something in particular (e.g. a dog that can be pet). These are not\n",
    "# useful to us, and removing them might make our dataset much more reflective of a more average user-- the true audience we \n",
    "# are trying to get at.\n",
    "\n",
    "# Let's try another way of identifying the outliers: 3x STDev (if it falls beyond 3 standard deviations from the mean, it\n",
    "# is an outlier).\n",
    "\n",
    "ceil_reviews = users_df[\"reviews\"].mean() + 3*users_df[\"reviews\"].std() # ~26.8\n",
    "# We don't bother with a lower bound; it would be a negative number in this case since the data is skewed so hard one direction.\n",
    "\n",
    "reviews_outliers = users_df[(users_df[\"reviews\"] > ceil_reviews)] # If reviews >= 27, then exclude\n",
    "\n",
    "display(reviews_outliers.sort_values(by = \"reviews\"))\n",
    "\n",
    "print(f\"As anticipated, our outliers range 27 to 6045 reviews. The number of outliers actually represents <\",end=\"\")\n",
    "print(f\"{math.ceil(100*reviews_outliers.shape[0]/users_df.shape[0])}% of total reviews.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3f82aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df_clean = users_df.drop(reviews_outliers.index).sort_values(by = \"reviews\")\n",
    "display(users_df_clean)\n",
    "\n",
    "print(\"This represents the vast majority of reviewers, and hopefully cuts out many non-human reviewers.\")\n",
    "print(\"I don't think it makes too much sense to also curtail by number of products a reviewer has.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0229ab41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2.c recom_df examination for outliers\n",
    "\n",
    "recom_df.describe()   # Note: may take a long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e3cb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2.c continued\n",
    "# Importantly, this information already is cut off: any user with >=1000 hours in a game is recorded as having ~1000 hours.\n",
    "\n",
    "# Otherwise, the \"helpful\" and \"funny\" metrics don't seem to matter much. This is how much other users engage with a review.\n",
    "\n",
    "# It might make sense to cut out the reviews with the least hours played, but even these are important: some games are extremely\n",
    "# short, or some people may be simply unable to launch the game they've purchased.\n",
    "\n",
    "# The other metrics are ID numbers, so no need to check for further outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b02c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2.d\n",
    "# And finally, the metadata (games_metadata.json)\n",
    "gmeta_df.describe()\n",
    "\n",
    "print(\"Since there isn't a numerical value outside app_id, we won't bother further examining games_metadata.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28a8da6",
   "metadata": {},
   "source": [
    "### 3.3 Data Quality and Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc87d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3.1 Ensured data quality by verifying data consistency and accuracy.\n",
    "\n",
    "# We performed a check for missing values already. But if we're going to strike some entries in users_df, we should strike\n",
    "# those users from the recom_df too.\n",
    "\n",
    "display(reviews_outliers)\n",
    "print(\"We will have to remove all entries with these user_id numbers from recom_df.\\nThis amounts to\",end=\" \")\n",
    "print(f\"{reviews_outliers['reviews'].sum()} entries, so {recom_df.shape[0]-reviews_outliers['reviews'].sum()} will remain.\")\n",
    "display(recom_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5722a40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3.1 continued\n",
    "\n",
    "# We remove all entries from recom_df that have a user_id contained in reviews_outliers:\n",
    "recom_df_clean = recom_df[~recom_df[\"user_id\"].isin(reviews_outliers[\"user_id\"])]\n",
    "display(recom_df_clean)\n",
    "\n",
    "# Verify that these two numbers are the same: that means that we dropped exactly as many entries as we wanted to.\n",
    "print(f\"As expected, {recom_df.shape[0]-reviews_outliers['reviews'].sum()} = {recom_df_clean.shape[0]}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b681ae37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3.2 Check for duplicate records or potential errors; correct them as needed.\n",
    "\n",
    "# Duplicates are simple:\n",
    "print(f\"games_df contains {games_df.duplicated().sum()} duplicates.\")\n",
    "print(f\"users_df_clean contains {users_df_clean.duplicated().sum()} duplicates.\")\n",
    "print(f\"recom_df_clean contains {recom_df_clean.duplicated().sum()} duplicates.\")  # Warning, takes a long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b912ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3.3 If a transformation was made, what was it and why?\n",
    "\n",
    "# We made sure that all the outlier reviewers that had made too many reviews in users_df were also struck from recom_df; this\n",
    "# means that our products (users_df_clean and recom_df_clean) will not have orphaned user_id numbers that exist in one and not  \n",
    "# the other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8244d70f",
   "metadata": {},
   "source": [
    "### 3.4 Data Preparation for Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e876fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It has become obvious at this point that the most important dataset we're working with is the recommendations.csv, and our\n",
    "# version of it: recom_df_clean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26d2a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6be34b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
